{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c939f68c-ab90-4d8b-8f81-0f9a9d832ac1",
   "metadata": {},
   "source": [
    "# Building a TF Model\n",
    "Trying some code snippets from Fran√ßois Chollet's \"Deep Learning with Python\", Chapter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac719f9-f3df-4385-9c6d-43e52a015efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a33589-01bb-427a-8d5e-86356ae8cec3",
   "metadata": {},
   "source": [
    "## Building Custom Layer using `keras.layers.Layer`\n",
    "Standard affine transformation `y = W*X+b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a03b01f-6728-423e-b222-1eed14da87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.W = self.add_weight(\n",
    "            shape=(input_dim, self.units), \n",
    "            initializer=\"random_normal\")\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"zeros\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        y = tf.matmul(inputs, self.W) + self.b\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c717b9-2d30-44b3-9435-c9ac07710f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n"
     ]
    }
   ],
   "source": [
    "my_dense = SimpleDense(units=32, activation=tf.nn.relu)\n",
    "input_tensor = tf.ones(shape=(2, 784))\n",
    "output_tensor = my_dense(input_tensor)\n",
    "\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61815ada-fd53-4d79-b110-649e5499306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(32)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59f149-e356-4e4e-9de5-82a7425838c0",
   "metadata": {},
   "source": [
    "## Automatic Shape Inference in TF\n",
    "```python\n",
    "def __call__(self, inputs):\n",
    "    if not self.built:\n",
    "        self.build(inputs.shape)\n",
    "        self.built = True\n",
    "    return self.call(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f6ee58-6fe4-4d64-ab5e-b380f3656491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    SimpleDense(32, activation=\"relu\"),\n",
    "    SimpleDense(64, activation=\"relu\"),\n",
    "    SimpleDense(32, activation=\"relu\"),\n",
    "    SimpleDense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656119bf-5ade-4935-a250-aeaa1cf5233a",
   "metadata": {},
   "source": [
    "## Sample Compilation Step\n",
    "Metrics are for analysis and are not optimized. They don't need to be differentiable.\n",
    "### Some default optimizers:\n",
    "- SGD (with or without momentum)\n",
    "- RMSprop\n",
    "- Adam\n",
    "- Adagrad\n",
    "\n",
    "### Some default losses:\n",
    "- CategoricalCrossentropy\n",
    "- SparseCategoricalCrossentropy\n",
    "- BinaryCrossentropy\n",
    "- MeanSquaredError\n",
    "- KLDivergence\n",
    "- CosineSimilarity\n",
    "\n",
    "### Metrics:\n",
    "- CategoricalAccuracy\n",
    "- SparseCategoricalAccuracy\n",
    "- BinaryAccuracy\n",
    "- AUC\n",
    "- Precision\n",
    "- Recall\n",
    "\n",
    "### Customizing compilation \n",
    "```python\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss=my_custom_loss,\n",
    "              metrics=[my_custom_metric_1, my_custom_metric_2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2aaab7c-d4ef-4740-ac42-8c2a9cf0cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# Equivalent\n",
    "# model.compile(optimizer=keras.optimizers.RMSprop(), \n",
    "              # loss=keras.losses.MeanSquaredError(),\n",
    "              # metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b04d7c-a4fc-4d58-a21a-6d25381eeed0",
   "metadata": {},
   "source": [
    "## Fitting your model with `fit()`\n",
    "Pass in\n",
    "- Data: inputs and targets\n",
    "    - Either numpy arrays or TF `Dataset` object\n",
    "- Epochs to train for\n",
    "- Batch size with each epoch of mini-batch GD\n",
    "\n",
    "```python\n",
    "history = model.fit(\n",
    "    inputs,\n",
    "    targets,\n",
    "    epochs=5,\n",
    "    batch_size=128\n",
    ")\n",
    "```\n",
    "\n",
    "History objects, which is a dict mapping keys (e.g. \"loss\") or specific metric names to the list of per-epoch values\n",
    "\n",
    "### Validation\n",
    "Use validation sets to see how data is doing per epoch on values your model hasn't seen before. \n",
    "Pass in the `validation_data=(val_inputs, val_targets` within `model.fit()`\n",
    "\n",
    "Seeing validation loss and metrics after training is complete, you can use `evaluate()`\n",
    "\n",
    "```python\n",
    "loss_and_metrics = model.evaluate(val_inputs, val_targets, batch_size=128)\n",
    "```\n",
    "\n",
    "## Model Inference\n",
    "I.E. predictions on new data. Use `__call__()` method, which is called by default using the variable name.\n",
    "\n",
    "```python\n",
    "predictions = model(new_inputs)\n",
    "```\n",
    "However, this tries to process all inputs at once, which may not be feasible depending on your processing power. \n",
    "We can use `predict()` instead. The batch_size decides how many it does at once)\n",
    "\n",
    "```python\n",
    "predictions = model.predict(new_inputs, batch_size=128)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19682c-4d0a-40c4-b7cd-e69f89d3779c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
